= Google Cloud Vertex AI
include::_graphacademy_llm.adoc[]
:slug: google-cloud-demo
:author: Ben Lackey, Michael Hunger
:category: genai-ecosystem
:tags: rag, demo, retrieval augmented generation, chatbot, google, vertexai, gemini, langchain, reasoning-engine
:neo4j-versions: 5.x
:page-pagination:
:page-product: google-cloud-demo
:imagesdir: https://dev.assets.neo4j.com/wp-content/uploads/2024/

== Deploying GenAI Applications and APIs with Vertex AI Reasoning Engine

GenAI developers, familiar with orchestration tools and architectures often face challenges when deploying their work to production. 
Google's https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/overview[Vertex AI Reasoning Engine Runtime^](preview) now offers an easy way to deploy, scale, and monitor GenAI applications and APIs without in-depth knowledge of containers or cloud configurations. 

Compatible with various orchestration frameworks, including xref:langchain.adoc[LangChain], this solution allows developers to use the https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk[Vertex AI Python SDK^] for setup, testing, deployment.

It works like this:

- Create a Python class for your GenAI app class to store environment info and static data in the constructor.
- Initialize your orchestration framework in a `set_up` method at  startup.
- Process user queries with a `query` method, returning text responses.
- Deploy your GenAI API with `llm_extension.ReasoningEngine.create`, including class instance and requirements.

Our new integrations with Google Cloud, combined with our extensive LangChain integrations, allow you to seamlessly incorporate Neo4j knowledge graphs into your GenAI stack. 
You can use LangChain and other orchestration tools to deploy RAG architectures, like GraphRAG, with Reasoning Engine Runtime.

You can see below an example of GraphRAG on a Company News Knowledge Graph using LangChain, Neo4j and Gemini.

image::reasoning-engine-graphrag.png[]

== Knowledge Graph Generation with Gemini Pro

The xref:llm-graph-builder.adoc[LLM Graph Builder] that extracts entities from unstructured text (PDFs, YouTube Transcripts, Wikipedia) can be configured to use VertexAI both as embedding model and Gemnini as LLM for the extraction.
PDFs can be also be loaded from Google Cloud buckets.

It uses the underlying llm-graph-transformer library that we contributed to LangChain.

// TODO image

// The Demo is available https://llm-graph-builder-gemini.neo4jlabs.com[online with with Google Gemini on Vertex AI^].

== SEC Filings GenAI Labs 

This example consists of two sample applications that show how to use Neo4j with the generative AI capabilities in Google Cloud Vertex AI. We explore how to leverage Google generative AI to build and consume a knowledge graph in Neo4j.

* assetmanager - Parses data from the SEC containing quarterly filings of asset managers. We build a graph containing assets managers and the securities they hold. A chatbot that queries the knowledge graph is included as well.
* resume - Extracts entities like jobs and skills from a collection of resumes, then builds a graphs showing what talents individuals share. A chatbot that queries the knowledge graph is included as well.

=== Installation

The Demo is available on GitHub: https://github.com/neo4j-partners/neo4j-generative-ai-google-cloud

=== Relevant Links

[cols="1,4"]
|===
| icon:github[] Code Repository | https://github.com/neo4j-partners/neo4j-generative-ai-google-cloud[GitHub]
| Blog Post | https://cloud.google.com/blog/topics/partners/build-intelligent-apps-with-neo4j-and-google-generative-ai[Link]
| Demo Video | https://www.youtube.com/watch?v=UGWVMfo5Pew[Link]
| Slides | https://docs.google.com/presentation/d/1vIXaZCWX5fN5m6y50Z7nM6RlTSJR7vErUrfXlWR0BLY/edit?usp=sharing[Link]
| Press Release | https://neo4j.com/press-releases/neo4j-google-cloud-vertex-ai[Link]
|===

=== Videos & Tutorials

++++
<iframe width="640" height="480" src="https://www.youtube.com/embed/UGWVMfo5Pew" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
++++
